{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch has version 2.0.0+cu117 with cuda 11.7\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "!pip install torch_geometric\n",
    "from torch_geometric.nn import MessagePassing, radius_graph\n",
    "\n",
    "print(f\"PyTorch has version {torch.__version__} with cuda {torch.version.cuda}\")\n",
    "\n",
    "\n",
    "import reading_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
    "import torch_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "if not os.path.exists('./Sand'):\n",
    "    gdown.download_folder(\"https://drive.google.com/drive/folders/1w-aWuQJEr2BqDkEMQdcKnRBBJapwLtBT\")\n",
    "\n",
    "ds_train = torch.load('Sand/train.pt')\n",
    "ds_test = torch.load('Sand/test.pt')\n",
    "ds_valid = torch.load('Sand/valid.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"c:\\Users\\Jeffrey\\.conda\\envs\\182project\\Lib\\site-packages\\torch_cluster\\radius.py\", line 118, in radius_graph\n\n    assert flow in ['source_to_target', 'target_to_source']\n    edge_index = radius(x, x, r, batch, batch,\n                 ~~~~~~ <--- HERE\n                        max_num_neighbors if loop else max_num_neighbors + 1,\n                        num_workers)\n  File \"c:\\Users\\Jeffrey\\.conda\\envs\\182project\\Lib\\site-packages\\torch_cluster\\radius.py\", line 72, in radius\n        ptr_y = torch.bucketize(arange, batch_y)\n\n    return torch.ops.torch_cluster.radius(x, y, ptr_x, ptr_y, r,\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n                                          max_num_neighbors, num_workers)\nRuntimeError: Not compiled with CUDA support\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 571\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    570\u001b[0m     simulator\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m--> 571\u001b[0m train(simulator)\n\u001b[0;32m    572\u001b[0m \u001b[39m# infer(simulator)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[25], line 504\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(simulator)\u001b[0m\n\u001b[0;32m    501\u001b[0m non_kinematic_mask \u001b[39m=\u001b[39m (features[\u001b[39m'\u001b[39m\u001b[39mparticle_type\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mclone()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m    502\u001b[0m sampled_noise \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m non_kinematic_mask\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m--> 504\u001b[0m pred, target \u001b[39m=\u001b[39m simulator\u001b[39m.\u001b[39;49mpredict_accelerations(\n\u001b[0;32m    505\u001b[0m     next_position\u001b[39m=\u001b[39;49mlabels, \n\u001b[0;32m    506\u001b[0m     position_sequence_noise\u001b[39m=\u001b[39;49msampled_noise, \n\u001b[0;32m    507\u001b[0m     position_sequence\u001b[39m=\u001b[39;49mfeatures[\u001b[39m'\u001b[39;49m\u001b[39mposition\u001b[39;49m\u001b[39m'\u001b[39;49m], \n\u001b[0;32m    508\u001b[0m     n_particles_per_example\u001b[39m=\u001b[39;49mfeatures[\u001b[39m'\u001b[39;49m\u001b[39mn_particles_per_example\u001b[39;49m\u001b[39m'\u001b[39;49m], \n\u001b[0;32m    509\u001b[0m     particle_types\u001b[39m=\u001b[39;49mfeatures[\u001b[39m'\u001b[39;49m\u001b[39mparticle_type\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    510\u001b[0m )\n\u001b[0;32m    511\u001b[0m loss \u001b[39m=\u001b[39m (pred \u001b[39m-\u001b[39m target) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m    512\u001b[0m loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39msum(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[25], line 346\u001b[0m, in \u001b[0;36mSimulator.predict_accelerations\u001b[1;34m(self, next_position, position_sequence_noise, position_sequence, n_particles_per_example, particle_types)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_accelerations\u001b[39m(\u001b[39mself\u001b[39m, next_position, position_sequence_noise, position_sequence, n_particles_per_example, particle_types):\n\u001b[0;32m    345\u001b[0m     noisy_position_sequence \u001b[39m=\u001b[39m position_sequence \u001b[39m+\u001b[39m position_sequence_noise\n\u001b[1;32m--> 346\u001b[0m     node_features, edge_index, e_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_graph_from_raw(noisy_position_sequence, n_particles_per_example, particle_types)\n\u001b[0;32m    347\u001b[0m     predicted_normalized_acceleration \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_encode_process_decode(node_features, edge_index, e_features)\n\u001b[0;32m    348\u001b[0m     next_position_adjusted \u001b[39m=\u001b[39m next_position \u001b[39m+\u001b[39m position_sequence_noise[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "Cell \u001b[1;32mIn[25], line 270\u001b[0m, in \u001b[0;36mSimulator._build_graph_from_raw\u001b[1;34m(self, position_sequence, n_particles_per_example, particle_types)\u001b[0m\n\u001b[0;32m    268\u001b[0m velocity_sequence \u001b[39m=\u001b[39m time_diff(position_sequence)\n\u001b[0;32m    269\u001b[0m \u001b[39m# senders and receivers are integers of shape (E,)\u001b[39;00m\n\u001b[1;32m--> 270\u001b[0m senders, receivers \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_connectivity(most_recent_position, n_particles_per_example, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_connectivity_radius)\n\u001b[0;32m    271\u001b[0m node_features \u001b[39m=\u001b[39m []\n\u001b[0;32m    272\u001b[0m \u001b[39m# Normalized velocity sequence, merging spatial an time axis.\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[25], line 316\u001b[0m, in \u001b[0;36mSimulator._compute_connectivity\u001b[1;34m(self, node_features, n_particles_per_example, radius, add_self_edges)\u001b[0m\n\u001b[0;32m    314\u001b[0m batch_ids \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([torch\u001b[39m.\u001b[39mLongTensor([i \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n)]) \u001b[39mfor\u001b[39;00m i, n \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(n_particles_per_example)])\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_device)\n\u001b[0;32m    315\u001b[0m \u001b[39m# radius = radius + 0.00001 # radius_graph takes r < radius not r <= radius\u001b[39;00m\n\u001b[1;32m--> 316\u001b[0m edge_index \u001b[39m=\u001b[39m radius_graph(node_features, r\u001b[39m=\u001b[39;49mradius, batch\u001b[39m=\u001b[39;49mbatch_ids, loop\u001b[39m=\u001b[39;49madd_self_edges) \u001b[39m# (2, n_edges)\u001b[39;00m\n\u001b[0;32m    317\u001b[0m receivers \u001b[39m=\u001b[39m edge_index[\u001b[39m0\u001b[39m, :]\n\u001b[0;32m    318\u001b[0m senders \u001b[39m=\u001b[39m edge_index[\u001b[39m1\u001b[39m, :]\n",
      "File \u001b[1;32mc:\\Users\\Jeffrey\\.conda\\envs\\182project\\Lib\\site-packages\\torch_geometric\\nn\\pool\\__init__.py:210\u001b[0m, in \u001b[0;36mradius_graph\u001b[1;34m(x, r, batch, loop, max_num_neighbors, flow, num_workers)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mradius_graph\u001b[39m(x: Tensor, r: \u001b[39mfloat\u001b[39m, batch: OptTensor \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    176\u001b[0m                  loop: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, max_num_neighbors: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m32\u001b[39m,\n\u001b[0;32m    177\u001b[0m                  flow: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39msource_to_target\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    178\u001b[0m                  num_workers: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m    179\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Computes graph edges to all points within a given distance.\u001b[39;00m\n\u001b[0;32m    180\u001b[0m \n\u001b[0;32m    181\u001b[0m \u001b[39m    .. code-block:: python\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[39m    :rtype: :class:`torch.Tensor`\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 210\u001b[0m     \u001b[39mreturn\u001b[39;00m torch_cluster\u001b[39m.\u001b[39;49mradius_graph(x, r, batch, loop, max_num_neighbors,\n\u001b[0;32m    211\u001b[0m                                       flow, num_workers)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"c:\\Users\\Jeffrey\\.conda\\envs\\182project\\Lib\\site-packages\\torch_cluster\\radius.py\", line 118, in radius_graph\n\n    assert flow in ['source_to_target', 'target_to_source']\n    edge_index = radius(x, x, r, batch, batch,\n                 ~~~~~~ <--- HERE\n                        max_num_neighbors if loop else max_num_neighbors + 1,\n                        num_workers)\n  File \"c:\\Users\\Jeffrey\\.conda\\envs\\182project\\Lib\\site-packages\\torch_cluster\\radius.py\", line 72, in radius\n        ptr_y = torch.bucketize(arange, batch_y)\n\n    return torch.ops.torch_cluster.radius(x, y, ptr_x, ptr_y, r,\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n                                          max_num_neighbors, num_workers)\nRuntimeError: Not compiled with CUDA support\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MessagePassing, radius_graph\n",
    "import functools\n",
    "import tensorflow.compat.v1 as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import reading_utils\n",
    "import tree\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "os.makedirs('train_log', exist_ok=True)\n",
    "os.makedirs('rollouts', exist_ok=True)\n",
    "\n",
    "INPUT_SEQUENCE_LENGTH = 6\n",
    "batch_size = 2\n",
    "noise_std = 6.7e-4\n",
    "training_steps = 2000\n",
    "log_steps = 100\n",
    "eval_steps = 2000\n",
    "save_steps = 1000\n",
    "model_path = None # 'model425000.pth'\n",
    "device = 'cuda'\n",
    "data_dir = 'Sand/'\n",
    "with open(data_dir + 'metadata.json', 'rt') as f:\n",
    "    metadata = json.loads(f.read())\n",
    "num_steps = metadata['sequence_length'] - INPUT_SEQUENCE_LENGTH\n",
    "normalization_stats = {\n",
    "    'acceleration': {\n",
    "        'mean':torch.FloatTensor(metadata['acc_mean']).to(device), \n",
    "        'std':torch.sqrt(torch.FloatTensor(metadata['acc_std'])**2 + noise_std**2).to(device),\n",
    "    }, \n",
    "    'velocity': {\n",
    "        'mean':torch.FloatTensor(metadata['vel_mean']).to(device), \n",
    "        'std':torch.sqrt(torch.FloatTensor(metadata['vel_std'])**2 + noise_std**2).to(device),\n",
    "    }, \n",
    "}\n",
    "\n",
    "def build_mlp(\n",
    "    input_size,\n",
    "    layer_sizes,\n",
    "    output_size=None,\n",
    "    output_activation=torch.nn.Identity,\n",
    "    activation=torch.nn.ReLU,\n",
    "):\n",
    "    sizes = [input_size] + layer_sizes\n",
    "    if output_size:\n",
    "        sizes.append(output_size)\n",
    "\n",
    "    layers = []\n",
    "    for i in range(len(sizes) - 1):\n",
    "        act = activation if i < len(sizes) - 2 else output_activation\n",
    "        layers += [torch.nn.Linear(sizes[i], sizes[i + 1]), act()]\n",
    "    return torch.nn.Sequential(*layers)\n",
    "\n",
    "def time_diff(input_sequence):\n",
    "    return input_sequence[:, 1:] - input_sequence[:, :-1]\n",
    "\n",
    "def get_random_walk_noise_for_position_sequence(position_sequence, noise_std_last_step):\n",
    "    \"\"\"Returns random-walk noise in the velocity applied to the position.\"\"\"\n",
    "    velocity_sequence = time_diff(position_sequence)\n",
    "    num_velocities = velocity_sequence.shape[1]\n",
    "    velocity_sequence_noise = torch.randn(list(velocity_sequence.shape)) * (noise_std_last_step/num_velocities**0.5)\n",
    "\n",
    "    velocity_sequence_noise = torch.cumsum(velocity_sequence_noise, dim=1)\n",
    "\n",
    "    position_sequence_noise = torch.cat([\n",
    "        torch.zeros_like(velocity_sequence_noise[:, 0:1]),\n",
    "        torch.cumsum(velocity_sequence_noise, dim=1)], dim=1)\n",
    "\n",
    "    return position_sequence_noise\n",
    "\n",
    "def _read_metadata(data_path):\n",
    "    with open(os.path.join(data_path, 'metadata.json'), 'rt') as fp:\n",
    "        return json.loads(fp.read())\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        node_in, \n",
    "        node_out, \n",
    "        edge_in, \n",
    "        edge_out,\n",
    "        mlp_num_layers,\n",
    "        mlp_hidden_dim,\n",
    "    ):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.node_fn = nn.Sequential(*[build_mlp(node_in, [mlp_hidden_dim for _ in range(mlp_num_layers)], node_out), \n",
    "            nn.LayerNorm(node_out)])\n",
    "        self.edge_fn = nn.Sequential(*[build_mlp(edge_in, [mlp_hidden_dim for _ in range(mlp_num_layers)], edge_out), \n",
    "            nn.LayerNorm(edge_out)])\n",
    "\n",
    "    def forward(self, x, edge_index, e_features): # global_features\n",
    "        # x: (E, node_in)\n",
    "        # edge_index: (2, E)\n",
    "        # e_features: (E, edge_in)\n",
    "        return self.node_fn(x), self.edge_fn(e_features)\n",
    "\n",
    "class InteractionNetwork(MessagePassing):\n",
    "    def __init__(\n",
    "        self, \n",
    "        node_in, \n",
    "        node_out, \n",
    "        edge_in, \n",
    "        edge_out,\n",
    "        mlp_num_layers,\n",
    "        mlp_hidden_dim,\n",
    "    ):\n",
    "        super(InteractionNetwork, self).__init__(aggr='add')\n",
    "        self.node_fn = nn.Sequential(*[build_mlp(node_in+edge_out, [mlp_hidden_dim for _ in range(mlp_num_layers)], node_out), \n",
    "            nn.LayerNorm(node_out)])\n",
    "        self.edge_fn = nn.Sequential(*[build_mlp(node_in+node_in+edge_in, [mlp_hidden_dim for _ in range(mlp_num_layers)], edge_out), \n",
    "            nn.LayerNorm(edge_out)])\n",
    "\n",
    "    def forward(self, x, edge_index, e_features):\n",
    "        # x: (E, node_in)\n",
    "        # edge_index: (2, E)\n",
    "        # e_features: (E, edge_in)\n",
    "        x_residual = x\n",
    "        e_features_residual = e_features\n",
    "        x, e_features = self.propagate(edge_index=edge_index, x=x, e_features=e_features)\n",
    "        return x+x_residual, e_features+e_features_residual\n",
    "\n",
    "    def message(self, edge_index, x_i, x_j, e_features):\n",
    "        e_features = torch.cat([x_i, x_j, e_features], dim=-1)\n",
    "        e_features = self.edge_fn(e_features)\n",
    "        return e_features\n",
    "\n",
    "    def update(self, x_updated, x, e_features):\n",
    "        # x_updated: (E, edge_out)\n",
    "        # x: (E, node_in)\n",
    "        x_updated = torch.cat([x_updated, x], dim=-1)\n",
    "        x_updated = self.node_fn(x_updated)\n",
    "        return x_updated, e_features\n",
    "\n",
    "class Processor(MessagePassing):\n",
    "    def __init__(\n",
    "        self, \n",
    "        node_in, \n",
    "        node_out, \n",
    "        edge_in, \n",
    "        edge_out,\n",
    "        num_message_passing_steps,\n",
    "        mlp_num_layers,\n",
    "        mlp_hidden_dim,\n",
    "    ):\n",
    "        super(Processor, self).__init__(aggr='max')\n",
    "        self.gnn_stacks = nn.ModuleList([\n",
    "            InteractionNetwork(\n",
    "                node_in=node_in, \n",
    "                node_out=node_out,\n",
    "                edge_in=edge_in, \n",
    "                edge_out=edge_out,\n",
    "                mlp_num_layers=mlp_num_layers,\n",
    "                mlp_hidden_dim=mlp_hidden_dim,\n",
    "            ) for _ in range(num_message_passing_steps)])\n",
    "\n",
    "    def forward(self, x, edge_index, e_features):\n",
    "        for gnn in self.gnn_stacks:\n",
    "            x, e_features = gnn(x, edge_index, e_features)\n",
    "        return x, e_features\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        node_in, \n",
    "        node_out,\n",
    "        mlp_num_layers,\n",
    "        mlp_hidden_dim,\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.node_fn = build_mlp(node_in, [mlp_hidden_dim for _ in range(mlp_num_layers)], node_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (E, node_in)\n",
    "        return self.node_fn(x)\n",
    "\n",
    "class EncodeProcessDecode(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        node_in,\n",
    "        node_out,\n",
    "        edge_in,\n",
    "        latent_dim,\n",
    "        num_message_passing_steps,\n",
    "        mlp_num_layers,\n",
    "        mlp_hidden_dim,\n",
    "    ):\n",
    "        super(EncodeProcessDecode, self).__init__()\n",
    "        self._encoder = Encoder(\n",
    "            node_in=node_in, \n",
    "            node_out=latent_dim,\n",
    "            edge_in=edge_in, \n",
    "            edge_out=latent_dim,\n",
    "            mlp_num_layers=mlp_num_layers,\n",
    "            mlp_hidden_dim=mlp_hidden_dim,\n",
    "        )\n",
    "        self._processor = Processor(\n",
    "            node_in=latent_dim, \n",
    "            node_out=latent_dim,\n",
    "            edge_in=latent_dim, \n",
    "            edge_out=latent_dim,\n",
    "            num_message_passing_steps=num_message_passing_steps,\n",
    "            mlp_num_layers=mlp_num_layers,\n",
    "            mlp_hidden_dim=mlp_hidden_dim,\n",
    "        )\n",
    "        self._decoder = Decoder(\n",
    "            node_in=latent_dim,\n",
    "            node_out=node_out,\n",
    "            mlp_num_layers=mlp_num_layers,\n",
    "            mlp_hidden_dim=mlp_hidden_dim,\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, e_features):\n",
    "        # x: (E, node_in)\n",
    "        x, e_features = self._encoder(x, edge_index, e_features)\n",
    "        x, e_features = self._processor(x, edge_index, e_features)\n",
    "        x = self._decoder(x)\n",
    "        return x\n",
    "\n",
    "class Simulator(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        particle_dimension,\n",
    "        node_in,\n",
    "        edge_in,\n",
    "        latent_dim,\n",
    "        num_message_passing_steps,\n",
    "        mlp_num_layers,\n",
    "        mlp_hidden_dim,\n",
    "        connectivity_radius,\n",
    "        boundaries,\n",
    "        normalization_stats,\n",
    "        num_particle_types,\n",
    "        particle_type_embedding_size,\n",
    "        device='cuda',\n",
    "    ):\n",
    "        super(Simulator, self).__init__()\n",
    "        self._boundaries = boundaries\n",
    "        self._connectivity_radius = connectivity_radius\n",
    "        self._normalization_stats = normalization_stats\n",
    "        self._num_particle_types = num_particle_types\n",
    "\n",
    "        self._particle_type_embedding = nn.Embedding(num_particle_types, particle_type_embedding_size) # (9, 16)\n",
    "\n",
    "        self._encode_process_decode = EncodeProcessDecode(\n",
    "            node_in=node_in,\n",
    "            node_out=particle_dimension,\n",
    "            edge_in=edge_in,\n",
    "            latent_dim=latent_dim,\n",
    "            num_message_passing_steps=num_message_passing_steps,\n",
    "            mlp_num_layers=mlp_num_layers,\n",
    "            mlp_hidden_dim=mlp_hidden_dim,\n",
    "        )\n",
    "\n",
    "        self._device = device\n",
    "\n",
    "    def forward(self):\n",
    "        pass\n",
    "\n",
    "    def _build_graph_from_raw(self, position_sequence, n_particles_per_example, particle_types):\n",
    "        n_total_points = position_sequence.shape[0]\n",
    "        most_recent_position = position_sequence[:, -1] # (n_nodes, 2)\n",
    "        velocity_sequence = time_diff(position_sequence)\n",
    "        # senders and receivers are integers of shape (E,)\n",
    "        senders, receivers = self._compute_connectivity(most_recent_position, n_particles_per_example, self._connectivity_radius)\n",
    "        node_features = []\n",
    "        # Normalized velocity sequence, merging spatial an time axis.\n",
    "        velocity_stats = self._normalization_stats[\"velocity\"]\n",
    "        normalized_velocity_sequence = (velocity_sequence - velocity_stats['mean']) / velocity_stats['std']\n",
    "        flat_velocity_sequence = normalized_velocity_sequence.view(n_total_points, -1)\n",
    "        node_features.append(flat_velocity_sequence)\n",
    "\n",
    "        # Normalized clipped distances to lower and upper boundaries.\n",
    "        # boundaries are an array of shape [num_dimensions, 2], where the second\n",
    "        # axis, provides the lower/upper boundaries.\n",
    "        boundaries = torch.tensor(self._boundaries, requires_grad=False).float().to(self._device)\n",
    "        distance_to_lower_boundary = (most_recent_position - boundaries[:, 0][None])\n",
    "        distance_to_upper_boundary = (boundaries[:, 1][None] - most_recent_position)\n",
    "        distance_to_boundaries = torch.cat([distance_to_lower_boundary, distance_to_upper_boundary], dim=1)\n",
    "        normalized_clipped_distance_to_boundaries = torch.clamp(distance_to_boundaries / self._connectivity_radius, -1., 1.)\n",
    "        node_features.append(normalized_clipped_distance_to_boundaries)\n",
    "\n",
    "        if self._num_particle_types > 1:\n",
    "            particle_type_embeddings = self._particle_type_embedding(particle_types)\n",
    "            node_features.append(particle_type_embeddings)\n",
    "\n",
    "        # Collect edge features.\n",
    "        edge_features = []\n",
    "\n",
    "        # Relative displacement and distances normalized to radius\n",
    "        # (E, 2)\n",
    "        # normalized_relative_displacements = (\n",
    "        #     torch.gather(most_recent_position, 0, senders) - torch.gather(most_recent_position, 0, receivers)\n",
    "        # ) / self._connectivity_radius\n",
    "        normalized_relative_displacements = (\n",
    "            most_recent_position[senders, :] - most_recent_position[receivers, :]\n",
    "        ) / self._connectivity_radius\n",
    "        edge_features.append(normalized_relative_displacements)\n",
    "\n",
    "        normalized_relative_distances = torch.norm(normalized_relative_displacements, dim=-1, keepdim=True)\n",
    "        edge_features.append(normalized_relative_distances)\n",
    "\n",
    "        return torch.cat(node_features, dim=-1), torch.stack([senders, receivers]), torch.cat(edge_features, dim=-1)\n",
    "\n",
    "    def _compute_connectivity(self, node_features, n_particles_per_example, radius, add_self_edges=True):\n",
    "        # handle batches. Default is 2 examples per batch\n",
    "\n",
    "        # Specify examples id for particles/points\n",
    "        batch_ids = torch.cat([torch.LongTensor([i for _ in range(n)]) for i, n in enumerate(n_particles_per_example)]).to(self._device)\n",
    "        # radius = radius + 0.00001 # radius_graph takes r < radius not r <= radius\n",
    "        edge_index = radius_graph(node_features, r=radius, batch=batch_ids, loop=add_self_edges) # (2, n_edges)\n",
    "        receivers = edge_index[0, :]\n",
    "        senders = edge_index[1, :]\n",
    "        return receivers, senders\n",
    "\n",
    "    def _decoder_postprocessor(self, normalized_acceleration, position_sequence):\n",
    "        # The model produces the output in normalized space so we apply inverse\n",
    "        # normalization.\n",
    "        acceleration_stats = self._normalization_stats[\"acceleration\"]\n",
    "        acceleration = (\n",
    "            normalized_acceleration * acceleration_stats['std']\n",
    "        ) + acceleration_stats['mean']\n",
    "\n",
    "        # Use an Euler integrator to go from acceleration to position, assuming\n",
    "        # a dt=1 corresponding to the size of the finite difference.\n",
    "        most_recent_position = position_sequence[:, -1]\n",
    "        most_recent_velocity = most_recent_position - position_sequence[:, -2]\n",
    "\n",
    "        new_velocity = most_recent_velocity + acceleration  # * dt = 1\n",
    "        new_position = most_recent_position + new_velocity  # * dt = 1\n",
    "        return new_position\n",
    "\n",
    "    def predict_positions(self, current_positions, n_particles_per_example, particle_types):\n",
    "        node_features, edge_index, e_features = self._build_graph_from_raw(current_positions, n_particles_per_example, particle_types)\n",
    "        predicted_normalized_acceleration = self._encode_process_decode(node_features, edge_index, e_features)\n",
    "        next_position = self._decoder_postprocessor(predicted_normalized_acceleration, current_positions)\n",
    "        return next_position\n",
    "\n",
    "    def predict_accelerations(self, next_position, position_sequence_noise, position_sequence, n_particles_per_example, particle_types):\n",
    "        noisy_position_sequence = position_sequence + position_sequence_noise\n",
    "        node_features, edge_index, e_features = self._build_graph_from_raw(noisy_position_sequence, n_particles_per_example, particle_types)\n",
    "        predicted_normalized_acceleration = self._encode_process_decode(node_features, edge_index, e_features)\n",
    "        next_position_adjusted = next_position + position_sequence_noise[:, -1]\n",
    "        target_normalized_acceleration = self._inverse_decoder_postprocessor(next_position_adjusted, noisy_position_sequence)\n",
    "        return predicted_normalized_acceleration, target_normalized_acceleration\n",
    "\n",
    "    def _inverse_decoder_postprocessor(self, next_position, position_sequence):\n",
    "        \"\"\"Inverse of `_decoder_postprocessor`.\"\"\"\n",
    "        previous_position = position_sequence[:, -1]\n",
    "        previous_velocity = previous_position - position_sequence[:, -2]\n",
    "        next_velocity = next_position - previous_position\n",
    "        acceleration = next_velocity - previous_velocity\n",
    "\n",
    "        acceleration_stats = self._normalization_stats[\"acceleration\"]\n",
    "        normalized_acceleration = (acceleration - acceleration_stats['mean']) / acceleration_stats['std']\n",
    "        return normalized_acceleration\n",
    "\n",
    "    def save(self, path='model.pth'):\n",
    "        torch.save(self.state_dict(), path)\n",
    "\n",
    "    def load(self, path):\n",
    "        self.load_state_dict(torch.load(path))\n",
    "\n",
    "def prepare_data_from_tfds(data_path='Sand/train.tfrecord', is_rollout=False, batch_size=2):\n",
    "\n",
    "    #from tfrecord.torch.dataset import TFRecordDataset\n",
    "    def prepare_inputs(tensor_dict):\n",
    "        pos = tensor_dict['position']\n",
    "        pos = tf.transpose(pos, perm=[1, 0, 2])\n",
    "        target_position = pos[:, -1]\n",
    "        tensor_dict['position'] = pos[:, :-1]\n",
    "        num_particles = tf.shape(pos)[0]\n",
    "        tensor_dict['n_particles_per_example'] = num_particles[tf.newaxis]\n",
    "        if 'step_context' in tensor_dict:\n",
    "            tensor_dict['step_context'] = tensor_dict['step_context'][-2]\n",
    "            tensor_dict['step_context'] = tensor_dict['step_context'][tf.newaxis]\n",
    "        return tensor_dict, target_position\n",
    "    def batch_concat(dataset, batch_size):\n",
    "        windowed_ds = dataset.window(batch_size)\n",
    "        initial_state = tree.map_structure(lambda spec: tf.zeros(shape=[0] + spec.shape.as_list()[1:], dtype=spec.dtype),dataset.element_spec)\n",
    "        def reduce_window(initial_state, ds):\n",
    "            return ds.reduce(initial_state, lambda x, y: tf.concat([x, y], axis=0))\n",
    "        return windowed_ds.map(lambda *x: tree.map_structure(reduce_window, initial_state, x))\n",
    "    def prepare_rollout_inputs(context, features):\n",
    "        out_dict = {**context}\n",
    "        pos = tf.transpose(features['position'], [1, 0, 2])\n",
    "        target_position = pos[:, -1]\n",
    "        out_dict['position'] = pos[:, :-1]\n",
    "        out_dict['n_particles_per_example'] = [tf.shape(pos)[0]]\n",
    "        if 'step_context' in features:\n",
    "            out_dict['step_context'] = features['step_context']\n",
    "        out_dict['is_trajectory'] = tf.constant([True], tf.bool)\n",
    "        return out_dict, target_position\n",
    "\n",
    "    metadata = _read_metadata('Sand/')\n",
    "    ds = tf.data.TFRecordDataset(data_path)\n",
    "    ds = ds.map(functools.partial(reading_utils.parse_serialized_simulation_example, metadata=metadata))\n",
    "    if is_rollout:\n",
    "        ds = ds.map(prepare_rollout_inputs)\n",
    "    else:    \n",
    "        split_with_window = functools.partial(\n",
    "            reading_utils.split_trajectory,\n",
    "            window_length=6 + 1)\n",
    "        ds = ds.flat_map(split_with_window)\n",
    "        ds = ds.map(prepare_inputs)\n",
    "        ds = ds.repeat()\n",
    "        ds = ds.shuffle(512)\n",
    "        ds = batch_concat(ds, batch_size)\n",
    "    ds = tfds.as_numpy(ds)\n",
    "    # for i in range(100): # clear screen\n",
    "    #     print()\n",
    "    return ds\n",
    "\n",
    "def eval_single_rollout(simulator, features, num_steps, device):\n",
    "    initial_positions = features['position'][:, 0:INPUT_SEQUENCE_LENGTH]\n",
    "    ground_truth_positions = features['position'][:, INPUT_SEQUENCE_LENGTH:]\n",
    "    \n",
    "    current_positions = initial_positions\n",
    "    predictions = []\n",
    "    for step in range(num_steps):\n",
    "        next_position = simulator.predict_positions(\n",
    "            current_positions,\n",
    "            n_particles_per_example=features['n_particles_per_example'],\n",
    "            particle_types=features['particle_type'],\n",
    "        ) # (n_nodes, 2)\n",
    "        # Update kinematic particles from prescribed trajectory.\n",
    "        kinematic_mask = (features['particle_type'] == 3).clone().detach().to(device)\n",
    "        next_position_ground_truth = ground_truth_positions[:, step]\n",
    "        kinematic_mask = kinematic_mask.bool()[:, None].expand(-1, 2)\n",
    "        next_position = torch.where(kinematic_mask, next_position_ground_truth, next_position)\n",
    "        predictions.append(next_position)\n",
    "        current_positions = torch.cat([current_positions[:, 1:], next_position[:, None, :]], dim=1)\n",
    "    predictions = torch.stack(predictions) # (time, n_nodes, 2)\n",
    "    ground_truth_positions = ground_truth_positions.permute(1,0,2)\n",
    "    loss = (predictions - ground_truth_positions) ** 2\n",
    "    output_dict = {\n",
    "        'initial_positions': initial_positions.permute(1,0,2).cpu().numpy(),\n",
    "        'predicted_rollout': predictions.cpu().numpy(),\n",
    "        'ground_truth_rollout': ground_truth_positions.cpu().numpy(),\n",
    "        'particle_types': features['particle_type'].cpu().numpy(),\n",
    "    }\n",
    "    return output_dict, loss\n",
    "\n",
    "def eval_rollout(ds, simulator, num_steps, num_eval_steps=1, save_results=False, device='cuda'):\n",
    "    eval_loss = []\n",
    "    i = 0\n",
    "    simulator.eval()\n",
    "    with torch.no_grad():\n",
    "        for example_i, (features, labels) in enumerate(ds):\n",
    "            features['position'] = torch.tensor(features['position']).to(device) # (n_nodes, 600, 2)\n",
    "            features['n_particles_per_example'] = torch.tensor(features['n_particles_per_example']).to(device)\n",
    "            features['particle_type'] = torch.tensor(features['particle_type']).to(device)\n",
    "            labels = torch.tensor(labels).to(device)\n",
    "            example_rollout, loss = eval_single_rollout(simulator, features, num_steps, device)\n",
    "            example_rollout['metadata'] = metadata\n",
    "            eval_loss.append(loss)\n",
    "            if save_results:\n",
    "                example_rollout['metadata'] = metadata\n",
    "                filename = f'rollout_{example_i}.pkl'\n",
    "                filename = os.path.join('rollouts/', filename)\n",
    "                with open(filename, 'wb') as f:\n",
    "                    pickle.dump(example_rollout, f)\n",
    "            i += 1\n",
    "            if i >= num_eval_steps:\n",
    "                break\n",
    "    simulator.train()\n",
    "    return torch.stack(eval_loss).mean(0)\n",
    "\n",
    "def train(simulator):\n",
    "    i = 0\n",
    "    while os.path.isdir('train_log/run'+str(i)):\n",
    "        i += 1\n",
    "    LOG_DIR = 'train_log/run'+str(i)+'/'\n",
    "\n",
    "    writer = SummaryWriter(LOG_DIR)\n",
    "\n",
    "    lr_init = 1e-4\n",
    "    lr_min = 1e-6\n",
    "    lr_decay = 0.1\n",
    "    lr_decay_steps = int(5e6)\n",
    "    lr_new = lr_init\n",
    "    optimizer = torch.optim.Adam(simulator.parameters(), lr=lr_init)\n",
    "\n",
    "    ds = prepare_data_from_tfds(batch_size=batch_size)\n",
    "    # ds_eval = prepare_data_from_tfds(data_path='data/valid.tfrecord', is_rollout=True)\n",
    "\n",
    "    step = 0\n",
    "    for features, labels in ds:\n",
    "        features['position'] = torch.tensor(features['position']).to(device)\n",
    "        features['n_particles_per_example'] = torch.tensor(features['n_particles_per_example']).to(device)\n",
    "        features['particle_type'] = torch.tensor(features['particle_type']).to(device)\n",
    "        labels = torch.tensor(labels).to(device)\n",
    "\n",
    "        sampled_noise = get_random_walk_noise_for_position_sequence(features['position'], noise_std_last_step=noise_std).to(device)\n",
    "        non_kinematic_mask = (features['particle_type'] != 3).clone().detach().to(device)\n",
    "        sampled_noise *= non_kinematic_mask.view(-1, 1, 1)\n",
    "\n",
    "        pred, target = simulator.predict_accelerations(\n",
    "            next_position=labels, \n",
    "            position_sequence_noise=sampled_noise, \n",
    "            position_sequence=features['position'], \n",
    "            n_particles_per_example=features['n_particles_per_example'], \n",
    "            particle_types=features['particle_type'],\n",
    "        )\n",
    "        loss = (pred - target) ** 2\n",
    "        loss = loss.sum(dim=-1)\n",
    "        num_non_kinematic = non_kinematic_mask.sum()\n",
    "\n",
    "        loss = torch.where(non_kinematic_mask.bool(), loss, torch.zeros_like(loss))\n",
    "        loss = loss.sum() / num_non_kinematic\n",
    "\n",
    "        if step % log_steps == 0:\n",
    "            writer.add_scalar(\"training_loss\", loss, step)\n",
    "            writer.add_scalar(\"lr\", lr_new, step)\n",
    "            print(f'Training step: {step}/{training_steps}. Loss: {loss}.')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        lr_new = lr_init * (lr_decay ** (step/lr_decay_steps))\n",
    "        for g in optimizer.param_groups:\n",
    "            g['lr'] = lr_new\n",
    "\n",
    "        step += 1\n",
    "        \n",
    "        if step >= training_steps:\n",
    "            break\n",
    "\n",
    "        # if step % eval_steps == 0:\n",
    "        #     eval_loss = eval_rollout(ds_eval, simulator, num_steps, num_eval_steps=10, device=device)\n",
    "        #     writer.add_scalar(\"eval_loss\", eval_loss, step)\n",
    "\n",
    "        if step % save_steps == 0:\n",
    "            simulator.save(LOG_DIR+'model.pth')\n",
    "\n",
    "\n",
    "\n",
    "    simulator.save(LOG_DIR+'model.pth')\n",
    "\n",
    "def infer(simulator):\n",
    "    ds = prepare_data_from_tfds(data_path='Sand/valid.tfrecord', is_rollout=True)\n",
    "    eval_rollout(ds, simulator, num_steps=num_steps, save_results=True, device=device)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    simulator = Simulator(\n",
    "        particle_dimension=2,\n",
    "        node_in=30,\n",
    "        edge_in=3,\n",
    "        latent_dim=128,\n",
    "        num_message_passing_steps=10,\n",
    "        mlp_num_layers=2,\n",
    "        mlp_hidden_dim=128,\n",
    "        connectivity_radius=metadata['default_connectivity_radius'],\n",
    "        boundaries=np.array(metadata['bounds']),\n",
    "        normalization_stats=normalization_stats,\n",
    "        num_particle_types=9,\n",
    "        particle_type_embedding_size=16,\n",
    "        device=device,\n",
    "    )\n",
    "    if model_path is not None:\n",
    "        simulator.load(model_path)\n",
    "    if device == 'cuda':\n",
    "        simulator.cuda()\n",
    "    train(simulator)\n",
    "    # infer(simulator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer(simulator)\n",
    "!python -m render_rollouts --rollout_path=rollouts/rollout_0.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'particle_type': tensor([6, 6, 6,  ..., 6, 6, 6]),\n",
       " 'key': <tf.Tensor: shape=(), dtype=int64, numpy=0>,\n",
       " 'position': tensor([[[0.4210, 0.5497],\n",
       "          [0.4064, 0.5722],\n",
       "          [0.3917, 0.5945],\n",
       "          ...,\n",
       "          [0.5590, 0.1381],\n",
       "          [0.5590, 0.1381],\n",
       "          [0.5590, 0.1381]],\n",
       " \n",
       "         [[0.4105, 0.5519],\n",
       "          [0.3959, 0.5744],\n",
       "          [0.3813, 0.5967],\n",
       "          ...,\n",
       "          [0.5227, 0.1448],\n",
       "          [0.5227, 0.1448],\n",
       "          [0.5227, 0.1448]],\n",
       " \n",
       "         [[0.4101, 0.5444],\n",
       "          [0.3955, 0.5670],\n",
       "          [0.3809, 0.5893],\n",
       "          ...,\n",
       "          [0.5404, 0.1396],\n",
       "          [0.5404, 0.1396],\n",
       "          [0.5404, 0.1397]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.6467, 0.6702],\n",
       "          [0.6564, 0.6687],\n",
       "          [0.6660, 0.6671],\n",
       "          ...,\n",
       "          [0.7642, 0.2511],\n",
       "          [0.7642, 0.2511],\n",
       "          [0.7642, 0.2511]],\n",
       " \n",
       "         [[0.8146, 0.6852],\n",
       "          [0.8243, 0.6838],\n",
       "          [0.8339, 0.6822],\n",
       "          ...,\n",
       "          [0.8362, 0.3816],\n",
       "          [0.8362, 0.3816],\n",
       "          [0.8362, 0.3816]],\n",
       " \n",
       "         [[0.8456, 0.6026],\n",
       "          [0.8552, 0.6012],\n",
       "          [0.8649, 0.5995],\n",
       "          ...,\n",
       "          [0.8361, 0.2178],\n",
       "          [0.8361, 0.2178],\n",
       "          [0.8361, 0.2178]]]),\n",
       " 'n_particles_per_example': tensor([1730], dtype=torch.int32),\n",
       " 'is_trajectory': tensor([True])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "182project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
